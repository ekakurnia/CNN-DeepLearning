{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tomato_Inception-v1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONNH2XPIaTSBtKuQG7ZeyC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekakurnia/CNN-DeepLearning/blob/master/Tomato_Inception_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3OYE9p4A9zo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06427724-71ff-4b30-a995-c365aed2cbc6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_oGOKvECH0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f8efe0c5-73fe-4161-a726-3a1dfc5dac50"
      },
      "source": [
        "%cd drive/'My Drive'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive'\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ifx7nrCIMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tivMQsV-CIJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = './Dataset/'\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY5alJPCCHx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXpSPVFECciv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c6d95502-da28-4f72-f5a5-af21f2429409"
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    %time print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Processing Tomato___Leaf_Mold ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
            "[INFO] Image loading completed\n",
            "CPU times: user 117 µs, sys: 27 µs, total: 144 µs\n",
            "Wall time: 148 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvHGcxncCc1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4341e82b-e0e3-401c-d472-a6c5d56657f9"
      },
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_2fkXhnCdPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ctLS5jACnyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "053b71c5-cf8d-4578-c3df-eafeebc68815"
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
            " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
            " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950lQMatCn-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnLLhVe_Cnvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21788fb6-c9b4-4a81-ac00-de2467cde611"
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdX35buDJAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAIE0jFpDI9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Inception Model\n",
        "\n",
        "# Impor paket yang diperlukan Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Inisialisasi Core\n",
        "kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "# Inisialisasi offset\n",
        "bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "\n",
        "# Fungsi yang menghasilkan Modul Inception\n",
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "\n",
        "    # Konvolusi 1 × 1\n",
        "    conv_1x1 = Conv2D(filters_1x1,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_1x1 = BatchNormalization()(conv_1x1)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3,\n",
        "                      (3, 3),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_3x3)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_5x5)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Max pooling\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk mencerna dimensi maksimum yang dikurangi\n",
        "    pool_proj = Conv2D(filters_pool_proj,\n",
        "                       (1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(pool_proj)\n",
        "    pool_proj = BatchNormalization()(pool_proj)\n",
        "\n",
        "    # Stack merge\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYFblPlYDI6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "516e64d2-c2d4-4a36-f0e3-8e63fd2e321c"
      },
      "source": [
        "# Impor paket yang diperlukan\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Mendefinisikan GoogleNet / Inception-V1\n",
        "class GoogleNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, channel, classes):\n",
        "\n",
        "        input_layer = Input(shape=(width, height, channel))\n",
        "\n",
        "        # Inisialisasi inti\n",
        "        kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        # Inisialisasi offset\n",
        "        bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (7, 7),\n",
        "                   padding='same',\n",
        "                   strides=(2, 2),\n",
        "                   activation='relu',\n",
        "                   name='conv_1_7x7/2')(input_layer)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (1, 1),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2a_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(192,\n",
        "                   (3, 3),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2b_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=64,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=128,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=32,\n",
        "                             filters_pool_proj=32,\n",
        "                             name='inception_3a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=192,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=96,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_3b')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=192,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=208,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=48,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=160,\n",
        "                             filters_3x3_reduce=112,\n",
        "                             filters_3x3=224,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4b')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=256,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4c')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=112,\n",
        "                             filters_3x3_reduce=144,\n",
        "                             filters_3x3=288,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4d')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_4e')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=384,\n",
        "                             filters_3x3_reduce=192,\n",
        "                             filters_3x3=384,\n",
        "                             filters_5x5_reduce=48,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5b')\n",
        "\n",
        "        # Global Avarage Pooling\n",
        "        x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "        # Random inactivation\n",
        "        x = Dropout(0.40)(x)\n",
        "\n",
        "        # Full connection/output\n",
        "        x = Dense(classes, activation='softmax', name='output')(x)\n",
        "\n",
        "        # Create GoogleNet model\n",
        "        # return Model(input_layer, [x, x1, x2], name='inception_v1')\n",
        "        return Model(input_layer, x, name='inception_v1')\n",
        "\n",
        "\n",
        "# Test GoogleNet class instantiation and output summary information of GoogleNet model\n",
        "if __name__ == \"__main__\":\n",
        "    model = GoogleNet.build(width=224, height=224, channel=3, classes=6)\n",
        "    print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1_7x7/2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv_1_7x7/2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_1_3x3/2 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_2a_3x3/1 (Conv2D)          (None, 56, 56, 64)   4160        max_pool_1_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv_2a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_2b_3x3/1 (Conv2D)          (None, 56, 56, 192)  110784      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 192)  768         conv_2b_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_3x3/2 (MaxPooling2D) (None, 28, 28, 192)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 96)   18528       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 16)   3088        max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 96)   384         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 28, 28, 192)  0           max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 64)   12352       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  110720      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 32)   12832       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 32)   6176        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 28, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a (Concatenate)      (None, 28, 28, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 32)   8224        inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 192)  221376      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 96)   76896       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 192)  768         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 96)   384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b (Concatenate)      (None, 28, 28, 480)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_3_3x3/2 (MaxPooling2D) (None, 14, 14, 480)  0           inception_3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 96)   46176       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 16)   7696        max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 96)   384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 480)  0           max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 192)  92352       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 208)  179920      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 48)   19248       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 192)  768         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 208)  832         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 48)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 112)  57456       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 24)   12312       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 14, 14, 112)  448         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 24)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 160)  82080       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 224)  226016      batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 14, 14, 160)  640         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 14, 14, 224)  896         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4b (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_21[0][0]     \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 24)   12312       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 14, 14, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 24)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 256)  295168      batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 128)  512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 64)   256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 64)   256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4c (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_27[0][0]     \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 144)  73872       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 32)   16416       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 144)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 112)  57456       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 288)  373536      batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 64)   51264       batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 112)  448         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 288)  1152        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 64)   256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4d (Concatenate)      (None, 14, 14, 528)  0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 160)  84640       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 32)   16928       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 160)  640         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 32)   128         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 528)  0           inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 256)  135424      inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 320)  461120      batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 128)  102528      batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 320)  1280        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e (Concatenate)      (None, 14, 14, 832)  0           batch_normalization_39[0][0]     \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_4_3x3/2 (MaxPooling2D) (None, 7, 7, 832)    0           inception_4e[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 160)    133280      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 32)     26656       max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    640         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 32)     128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 832)    0           max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 256)    213248      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 320)    461120      batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 128)    102528      batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 320)    1280        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 128)    512         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 128)    512         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a (Concatenate)      (None, 7, 7, 832)    0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    159936      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 48)     39984       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 192)    768         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 48)     192         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 832)    0           inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 384)    319872      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 384)    663936      batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 128)    153728      batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 384)    1536        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 384)    1536        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 128)    512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 128)    512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b (Concatenate)      (None, 7, 7, 1024)   0           batch_normalization_51[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool_5_3x3/1 (GlobalAverage (None, 1024)         0           inception_5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           avg_pool_5_3x3/1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 6)            6150        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,008,822\n",
            "Trainable params: 5,994,262\n",
            "Non-trainable params: 14,560\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWg56THvCHs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EFddykbDbFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUJsg_VlDbQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e126007d-c8a5-4d9c-b64e-83893ce0861c"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    validation_steps=1200// BS,\n",
        "    max_queue_size=BS*2,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.4853 - acc: 0.8412Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 2s 10ms/sample - loss: 0.4498 - acc: 0.8333\n",
            "30/30 [==============================] - 25s 831ms/step - loss: 0.4863 - acc: 0.8405 - val_loss: 0.4546 - val_acc: 0.8333\n",
            "Epoch 2/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.3285 - acc: 0.8759Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.7039 - acc: 0.7597\n",
            "30/30 [==============================] - 10s 320ms/step - loss: 0.3315 - acc: 0.8745 - val_loss: 0.6808 - val_acc: 0.7597\n",
            "Epoch 3/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.8991Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.0913 - acc: 0.7271\n",
            "30/30 [==============================] - 11s 355ms/step - loss: 0.2605 - acc: 0.9003 - val_loss: 1.0637 - val_acc: 0.7271\n",
            "Epoch 4/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9070Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.3023 - acc: 0.7229\n",
            "30/30 [==============================] - 11s 357ms/step - loss: 0.2379 - acc: 0.9071 - val_loss: 1.2835 - val_acc: 0.7229\n",
            "Epoch 5/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9319Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.3665 - acc: 0.7236\n",
            "30/30 [==============================] - 11s 355ms/step - loss: 0.1856 - acc: 0.9300 - val_loss: 1.3387 - val_acc: 0.7236\n",
            "Epoch 6/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9210Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.6219 - acc: 0.7222\n",
            "30/30 [==============================] - 11s 359ms/step - loss: 0.2083 - acc: 0.9219 - val_loss: 1.5681 - val_acc: 0.7222\n",
            "Epoch 7/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9316Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 3.3371 - acc: 0.7208\n",
            "30/30 [==============================] - 11s 358ms/step - loss: 0.1744 - acc: 0.9311 - val_loss: 3.2252 - val_acc: 0.7208\n",
            "Epoch 8/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9400Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 2.3288 - acc: 0.7292\n",
            "30/30 [==============================] - 11s 353ms/step - loss: 0.1528 - acc: 0.9405 - val_loss: 2.2582 - val_acc: 0.7292\n",
            "Epoch 9/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9422Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 2.8653 - acc: 0.7243\n",
            "30/30 [==============================] - 11s 356ms/step - loss: 0.1489 - acc: 0.9424 - val_loss: 2.8623 - val_acc: 0.7243\n",
            "Epoch 10/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9441Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 3.7397 - acc: 0.7236\n",
            "30/30 [==============================] - 11s 356ms/step - loss: 0.1431 - acc: 0.9443 - val_loss: 3.6279 - val_acc: 0.7236\n",
            "Epoch 11/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9553Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 3.3464 - acc: 0.7264\n",
            "30/30 [==============================] - 11s 353ms/step - loss: 0.1169 - acc: 0.9549 - val_loss: 3.2963 - val_acc: 0.7264\n",
            "Epoch 12/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9526Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 2.2091 - acc: 0.7493\n",
            "30/30 [==============================] - 11s 354ms/step - loss: 0.1327 - acc: 0.9526 - val_loss: 2.2232 - val_acc: 0.7493\n",
            "Epoch 13/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9610Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.0388 - acc: 0.8118\n",
            "30/30 [==============================] - 11s 355ms/step - loss: 0.1082 - acc: 0.9613 - val_loss: 0.9884 - val_acc: 0.8118\n",
            "Epoch 14/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9555Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.2391 - acc: 0.7701\n",
            "30/30 [==============================] - 11s 359ms/step - loss: 0.1122 - acc: 0.9549 - val_loss: 1.1322 - val_acc: 0.7701\n",
            "Epoch 15/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9632Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 2.2237 - acc: 0.7583\n",
            "30/30 [==============================] - 11s 353ms/step - loss: 0.1010 - acc: 0.9622 - val_loss: 2.1128 - val_acc: 0.7583\n",
            "Epoch 16/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9535Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3358 - acc: 0.8958\n",
            "30/30 [==============================] - 11s 351ms/step - loss: 0.1223 - acc: 0.9543 - val_loss: 0.3534 - val_acc: 0.8958\n",
            "Epoch 17/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9594Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.7019 - acc: 0.8424\n",
            "30/30 [==============================] - 11s 354ms/step - loss: 0.1205 - acc: 0.9585 - val_loss: 0.7441 - val_acc: 0.8424\n",
            "Epoch 18/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9565Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.9330 - acc: 0.8431\n",
            "30/30 [==============================] - 11s 352ms/step - loss: 0.1254 - acc: 0.9561 - val_loss: 0.7454 - val_acc: 0.8431\n",
            "Epoch 19/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9695Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.9851 - acc: 0.8160\n",
            "30/30 [==============================] - 11s 351ms/step - loss: 0.0881 - acc: 0.9698 - val_loss: 0.9433 - val_acc: 0.8160\n",
            "Epoch 20/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9635Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3320 - acc: 0.8771\n",
            "30/30 [==============================] - 10s 348ms/step - loss: 0.0915 - acc: 0.9635 - val_loss: 0.3713 - val_acc: 0.8771\n",
            "Epoch 21/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9738Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.2564 - acc: 0.9438\n",
            "30/30 [==============================] - 11s 353ms/step - loss: 0.0632 - acc: 0.9743 - val_loss: 0.2458 - val_acc: 0.9438\n",
            "Epoch 22/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9705Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.6802 - acc: 0.8701\n",
            "30/30 [==============================] - 11s 354ms/step - loss: 0.0882 - acc: 0.9712 - val_loss: 0.5525 - val_acc: 0.8701\n",
            "Epoch 23/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9696Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.7429 - acc: 0.8479\n",
            "30/30 [==============================] - 10s 346ms/step - loss: 0.0834 - acc: 0.9696 - val_loss: 0.7065 - val_acc: 0.8479\n",
            "Epoch 24/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9637Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3040 - acc: 0.9174\n",
            "30/30 [==============================] - 11s 351ms/step - loss: 0.1121 - acc: 0.9641 - val_loss: 0.3318 - val_acc: 0.9174\n",
            "Epoch 25/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9671Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.7201 - acc: 0.7944\n",
            "30/30 [==============================] - 10s 348ms/step - loss: 0.0904 - acc: 0.9681 - val_loss: 0.6981 - val_acc: 0.7944\n",
            "Epoch 26/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9752Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.4340 - acc: 0.8785\n",
            "30/30 [==============================] - 10s 344ms/step - loss: 0.0639 - acc: 0.9750 - val_loss: 0.4043 - val_acc: 0.8785\n",
            "Epoch 27/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9770Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.8265 - acc: 0.8104\n",
            "30/30 [==============================] - 10s 349ms/step - loss: 0.0638 - acc: 0.9760 - val_loss: 0.8315 - val_acc: 0.8104\n",
            "Epoch 28/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9661Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3376 - acc: 0.9028\n",
            "30/30 [==============================] - 11s 350ms/step - loss: 0.0840 - acc: 0.9660 - val_loss: 0.3565 - val_acc: 0.9028\n",
            "Epoch 29/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9738Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3188 - acc: 0.8986\n",
            "30/30 [==============================] - 11s 351ms/step - loss: 0.0724 - acc: 0.9738 - val_loss: 0.3714 - val_acc: 0.8986\n",
            "Epoch 30/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9784Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.4722 - acc: 0.8799\n",
            "30/30 [==============================] - 10s 349ms/step - loss: 0.0530 - acc: 0.9792 - val_loss: 0.4099 - val_acc: 0.8799\n",
            "Epoch 31/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9797Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.1849 - acc: 0.9368\n",
            "30/30 [==============================] - 10s 349ms/step - loss: 0.0557 - acc: 0.9800 - val_loss: 0.2512 - val_acc: 0.9368\n",
            "Epoch 32/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9765Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.2207 - acc: 0.9076\n",
            "30/30 [==============================] - 10s 348ms/step - loss: 0.0678 - acc: 0.9757 - val_loss: 0.3515 - val_acc: 0.9076\n",
            "Epoch 33/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9750Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.7459 - acc: 0.8250\n",
            "30/30 [==============================] - 10s 345ms/step - loss: 0.0685 - acc: 0.9759 - val_loss: 0.7259 - val_acc: 0.8250\n",
            "Epoch 34/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9795Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.7350 - acc: 0.8299\n",
            "30/30 [==============================] - 10s 348ms/step - loss: 0.0595 - acc: 0.9790 - val_loss: 0.8795 - val_acc: 0.8299\n",
            "Epoch 35/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9810Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3739 - acc: 0.9222\n",
            "30/30 [==============================] - 10s 349ms/step - loss: 0.0469 - acc: 0.9806 - val_loss: 0.2982 - val_acc: 0.9222\n",
            "Epoch 36/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9750Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.2288 - acc: 0.9097\n",
            "30/30 [==============================] - 10s 349ms/step - loss: 0.0669 - acc: 0.9752 - val_loss: 0.3224 - val_acc: 0.9097\n",
            "Epoch 37/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9808Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.4507 - acc: 0.8639\n",
            "30/30 [==============================] - 11s 352ms/step - loss: 0.0583 - acc: 0.9809 - val_loss: 0.5137 - val_acc: 0.8639\n",
            "Epoch 38/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9747Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.2466 - acc: 0.9118\n",
            "30/30 [==============================] - 11s 351ms/step - loss: 0.0673 - acc: 0.9745 - val_loss: 0.3449 - val_acc: 0.9118\n",
            "Epoch 39/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9797Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.3016 - acc: 0.9000\n",
            "30/30 [==============================] - 11s 350ms/step - loss: 0.0578 - acc: 0.9804 - val_loss: 0.3763 - val_acc: 0.9000\n",
            "Epoch 40/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9797Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.5632 - acc: 0.8618\n",
            "30/30 [==============================] - 11s 351ms/step - loss: 0.0522 - acc: 0.9800 - val_loss: 0.5249 - val_acc: 0.8618\n",
            "Epoch 41/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9736Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.3255 - acc: 0.7653\n",
            "30/30 [==============================] - 10s 347ms/step - loss: 0.0689 - acc: 0.9734 - val_loss: 1.1769 - val_acc: 0.7653\n",
            "Epoch 42/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9747Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.3893 - acc: 0.7451\n",
            "30/30 [==============================] - 10s 344ms/step - loss: 0.0696 - acc: 0.9745 - val_loss: 1.3090 - val_acc: 0.7451\n",
            "Epoch 43/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9772Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.8041 - acc: 0.7896\n",
            "30/30 [==============================] - 10s 346ms/step - loss: 0.0681 - acc: 0.9769 - val_loss: 0.8828 - val_acc: 0.7896\n",
            "Epoch 44/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9799Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.5648 - acc: 0.8507\n",
            "30/30 [==============================] - 11s 350ms/step - loss: 0.0574 - acc: 0.9799 - val_loss: 0.6438 - val_acc: 0.8507\n",
            "Epoch 45/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9793Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.4651 - acc: 0.8514\n",
            "30/30 [==============================] - 10s 349ms/step - loss: 0.0575 - acc: 0.9790 - val_loss: 0.5780 - val_acc: 0.8514\n",
            "Epoch 46/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9804Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.4624 - acc: 0.7812\n",
            "30/30 [==============================] - 11s 352ms/step - loss: 0.0465 - acc: 0.9811 - val_loss: 1.4011 - val_acc: 0.7812\n",
            "Epoch 47/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9783Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 1.1876 - acc: 0.8063\n",
            "30/30 [==============================] - 10s 347ms/step - loss: 0.0642 - acc: 0.9785 - val_loss: 1.2531 - val_acc: 0.8063\n",
            "Epoch 48/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9829Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.4282 - acc: 0.8861\n",
            "30/30 [==============================] - 10s 347ms/step - loss: 0.0483 - acc: 0.9833 - val_loss: 0.5008 - val_acc: 0.8861\n",
            "Epoch 49/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9876Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.6721 - acc: 0.8382\n",
            "30/30 [==============================] - 10s 345ms/step - loss: 0.0340 - acc: 0.9880 - val_loss: 0.6474 - val_acc: 0.8382\n",
            "Epoch 50/50\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9869Epoch 1/50\n",
            "240/30 [================================================================================================================================================================================================================================================] - 1s 2ms/sample - loss: 0.4710 - acc: 0.8972\n",
            "30/30 [==============================] - 10s 345ms/step - loss: 0.0398 - acc: 0.9863 - val_loss: 0.4363 - val_acc: 0.8972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9WEBvWTDhlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "7f2f7e6b-3836-491b-c8b4-1af16541247c"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npRcREAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRVGUGEEFXVEUJUZQQVcURYkR/h/uEbiVRPemUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfUG5HjSDhiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "edb28e29-c26f-45f4-cd1c-96b01596dfc7"
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Calculating model accuracy\n",
            "240/240 [==============================] - 0s 2ms/sample - loss: 0.4317 - acc: 0.8972\n",
            "Test Accuracy: 89.72222208976746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYkprLcIDbgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7q56lgdDbL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}